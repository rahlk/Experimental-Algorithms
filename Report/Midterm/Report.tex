\documentclass[conference]{IEEEtran}
%future work: local patch operator
%complexity
\usepackage{balance}
\usepackage{subfig}
\usepackage{wrapfig}
\usepackage{amsmath}
\usepackage{url}
\usepackage{pifont}
\pagenumbering{gobble}
%\usepackage{times}
\usepackage{rotating}
%\usepackage{balance} 
\usepackage{color, colortbl}
\usepackage{graphicx}
\usepackage{algorithmicx}
\usepackage[running]{lineno}
\usepackage{program}
\usepackage{cite}
\usepackage{alltt}
\usepackage{balance}
\newcommand{\eq}[1]{Equation~\ref{eq:#1}}
\newcommand{\bi}{\begin{itemize}}
	\newcommand{\ei}{\end{itemize}}
\newcommand{\be}{\begin{enumerate}}
	\newcommand{\ee}{\end{enumerate}}
\newcommand{\tion}[1]{\textsection\ref{sec:#1}}
\newcommand{\fig}[1]{Figure~\ref{fig:#1}}
\definecolor{lightgray}{gray}{0.975}
\usepackage{fancyvrb}
\usepackage{stfloats}
\usepackage{multirow}
\usepackage{listings}
\usepackage{amsmath}  
\DeclareMathOperator*{\argmin}{arg\,min} 
\DeclareMathOperator*{\argmax}{arg\,max} 
%\usepackage[usenames]{xcolor}
\bibliographystyle{unsrt}



\usepackage{color}
\newcommand{\colorrule}[1]{\begingroup\color{#1}\hrule\endgroup}

\definecolor{darkgreen}{rgb}{0,0.3,0}

\usepackage[table]{xcolor}
\definecolor{Gray}{rgb}{0.88,1,1}
\definecolor{Gray}{gray}{0.85}
\definecolor{Blue}{RGB}{0,29,193}
\newcommand{\G}{\cellcolor{green}}
\newcommand{\Y}{\cellcolor{yellow}}


\definecolor{MyDarkBlue}{rgb}{0,0.08,0.45} 
\newenvironment{changed}{\par\color{MyDarkBlue}}{\par}

\newcommand{\ADD}[1]{\textcolor{MyDarkBlue}{{\bf #1}}}
\newcommand{\addit}[1]{\begin{changed}\input{#1}\end{changed}}

\usepackage{color}
\usepackage{listings}
\usepackage{setspace}

\definecolor{Gray}{gray}{0.9}
\newcommand{\kw}[1]{\textit{#1}}
\newcommand{\quart}[4]{\begin{picture}(80,6)
	{\color{black}\put(#3,3){\circle*{2.5}}\put(#1,3){\line(1,0){#2}}}\end{picture}}
\newcommand{\tc}{\centering\arraybackslash}
\newcommand\topspace{\rule{0pt}{2.6ex}}       % Top strut
\newcommand{\stack}[3]{\vskip 1mm\shortstack{Min : #1 \\ Med : #2 \\ Max : #3}}

% New Commands

\definecolor{Code}{rgb}{0,0,0}
\definecolor{Decorators}{rgb}{0.5,0.5,0.5}
\definecolor{Numbers}{rgb}{0.5,0,0}
\definecolor{MatchingBrackets}{rgb}{0.25,0.5,0.5}
\definecolor{Keywords}{rgb}{0,0,1}
\definecolor{self}{rgb}{0,0,0}
\definecolor{Strings}{rgb}{0,0.63,0}
\definecolor{Comments}{rgb}{0,0.63,1}
\definecolor{Comments}{rgb}{0.5,0.5,0.5}
\definecolor{Backquotes}{rgb}{0,0,0}
\definecolor{Classname}{rgb}{0,0,0}
\definecolor{FunctionName}{rgb}{0,0,0}
\definecolor{Operators}{rgb}{0,0,0}
\definecolor{Background}{rgb}{1,1,1}
\author{Rahul Krishna, George Mathew\\
	Computer Science, North Carolina State University, USA\\
	\{rkrish11, george2\}\@ncsu.edu
}
\title{Evolutionary Multi-Objective Optimization:\\ A Distributed Computing approach}
\usepackage{etoolbox}
\makeatletter
\makeatother


\pagestyle{plain}
\begin{document}
	\maketitle
	\begin{abstract}

	\end{abstract}
	\begin{IEEEkeywords}
        Multi Objective Optimization, Parallelization, Evolutionary Algorithms, Domination, Pareto Frontier
	\end{IEEEkeywords}
	
	\section{Introduction} 
Optimization is the task of finding one or more solutions which satisfy one or more specified objectives. While a single-objective optimization involves a single objective function and a single solutions, a multi-objective optimization considers several objectives simultaneously. In such a  case, a multi-objective optimizer generates a set of alternate solution with certain trade-offs. These are called Pareto optimal solutions.

Multi-objective problems are usually complex, NP-Hard, and resource intensive. Although exact methods can be used, they consume prohibitively large amounts of time and memory. An alternative approach would be to make use of meta-heuristic algorithms, which approximate the Pareto frontier in a reasonable amount of time. Even so, these meta-heuristic algorithms consume a significant amount of time. 

Parallel and distributed computing used in design and implementation of these algorithms may offer significant speed-ups. In addition to this, they may be used to improve the quality, increase the robustness of the the obtained solutions, and may also allow the algorithms to be scaled to solve large problems. 

In this project, we aim to present parallel models for two evolutionary multi-objective optimizers: (1) Differential Evolution (DE) \cite{storn97}; and (2) Geometric Active Learning (GALE) \cite{krall15}. From the implementation point of view, we focus on using the \textit{henry2 Linux cluster} offered by NC State with distributed programming environments such as message passing (OpenMPI)~\cite{openMPI04}.

This report is organized as follows. The following section presents a brief description of the algorithms being studied. In \textsection\ref{measures}, we discuss various methods for evaluating the performance of the parallelized algorithms. In section \textsection\ref{challenges}, we highlight challenges we expect to overcome during implementation. Finally, section \textsection\ref{tools} highlights the tools we use.

\section{Methods and Materials}
\label{algos}

An Evolutionary Optimization(EO) begins its search with a population of solutions usually created at random within a specified lower and upper bound on each variable. If bounds are not supplied in an optimization problem, suitable values can be assumed only for the initialization purpose. Thereafter, the EO procedure enters into an iterative operation of updating the current population to create a new population by the use of four main operators: selection, crossover, mutation and elite-preservation. The operation stops when one or more termination criteria are met. The following evolutionary algorithms shall be parallelized.

\begin{enumerate}
\item \textbf{Differential Evolution (DE):} Differential evolution is a stochastic and population based optimization technique that iteratively tries to improve a candidate solution with respect to measure of quality. An objective function is defined in a selected region of the problem space. A candidate solution is then optimized to minimize/maximize the objective function based on the nature of the problem. Differential evolution offers the following advantages:

\begin{itemize}
\item It is computationally inexpensive.
\item It can handle problems with a high dimensionality. 
\item It allows the user to understand how the current solution was generated.
\end{itemize}

\item \textbf{Geometric Active Learning (GALE):} GALE is a near-linear time multi-objective optimization algorithm that builds a piecewise approximation to the surface of best solutions along the Pareto frontier. GALE uses a clustering algorithm called WHERE, which is powered by a FASTMAP \cite{faloutsos95}, to recursively reduce the dimensions to a single principal component. GALE offers the following advantages:

\begin{itemize}
\item It optimizes a problem with far fewer computations compared to other algorithms.
\item It is particularly adept at handling objective functions that are non-differentiable, non-linear, multidimensional, or are subject to multiple constraints.
\item It offers a very concise representation of the problem space due to WHERE.
\end{itemize}
\end{enumerate}

\section{Experiments}
Python is our choice of programming language. This is due to its support for efficient computation frameworks like numpy~\cite{numpy} and scipy~\cite{scipy} that enables quick prototyping and benchmarking.
For parallelization,  we used the OpenMPI implementation of the Message Passing Interface over a python wrapper. The Open MPI Project~\cite{openMPITool} is an open source Message Passing Interface implementation that is developed and maintained by a consortium of academic, research, and industry partners.The parallelized version of the algorithm is deployed and executed on HPC to measure the efficiency of the algorithm. The \textit{henry2}~\cite{ncsuHPC} shared memory linux cluster by NCSU may be used for this purpose. These nodes provide up to 16 shared memory processor cores and up to 128GB of memory accessible through a dedicated queue. 

For our experiments, we used 4 cores using 128 GB of shared memory

\subsection{Optimization Problem}
\label{problem}

Multi-objective Evolutionary Algorithms(MOEA) require scalable test problems that help test its efficiency. Our chosen test problem is a mathematical test problem \textbf{DTLZ2} \cite{debMOEA02}, which was formulated by \textit{Kalyanmoy \textbf{D}eb}, \textit{Lothar \textbf{T}hiele}, \textit{Marco \textbf{L}aumans} and \textit{Eckhart \textbf{Z}itzler}. 

\textbf{Decisions} : DTLZ2 has 30 decisions between 0 and 1.
\[0 \leq {x}_{i} \leq 1 \ \ \ \ where \ \  i = 1,2 ,3 .... 30\]

\textbf{Objectives} : Although DTLZ2 allows as to generate upto n-1 objectives where n is the number of decisions, we choose to limit the number of objectives to 3 since we can model the objectives better to visualize the pareto frontier. Limiting the number of objectives also controls the domination pressure. All the three objectives needs to be minimized. The objectives are defined as follows:
\[{f}_{1}(x) = (1+g({x}_{M}))\cos({x}_{1} \pi/2)....\cos({x}_{M-1} \pi/2)\]
\[{f}_{2}(x) = (1+g({x}_{M}))\cos({x}_{1} \pi/2)....\cos({x}_{M-1} \pi/2)\]
\[{f}_{3}(x) = (1+g({x}_{M}))\sin({x}_{1} \pi/2)\]
\[where \ \ \ \ g({x}_{M}) = \sum_{x \in {x}_{M}} (x_i - 0.5)^2 \]

\textbf{Optimal Solutions} : The pareto optimal solutions corresponds to the decisions \(x_i = 0.5\) and all objective function values must satisfy \(\sum_{m=1}^M (f_m)^2 = 1\). Figure \ref{fig:problem} shows the pareto frontier that represents the optimal solutions of DTLZ2.

\begin{figure}
\centering
\includegraphics{img/dtlz2_pareto.png}
\caption{Pareto Frontier of DTLZ2}
\label{fig:problem}
\end{figure}

\subsection{Measures}
\label{measures}
Figure \ref{fig:measure} highlights the performance evaluation measures we use to evaluate the algorithms.

\begin{figure}[h!]
\begin{tabular}{ll}
\hline
\rowcolor[HTML]{EFEFEF} 
\multicolumn{1}{l}{\cellcolor[HTML]{EFEFEF}{\bf Measure}} & \multicolumn{1}{c}{\cellcolor[HTML]{EFEFEF}{\bf  Description}}  \\ \hline
\rowcolor[HTML]{FFFFFF} 
{\bf Runtime}  & \begin{tabular}[l]{@{}l@{}}Time taken for the algorithm to be gener-\\ate optimal solutions.\end{tabular}\\\hline
{\bf Convergence}                                         & \begin{tabular}[l]{@{}l@{}}Convergence is the accuracy of the obtai-\\ned solutions. It mathematically repre-\\sents the hypervolume of the Pareto fro-\\ntier.In case of a  minimization problem,\\we expect it to be less and large in the\\case of a maximization problem.\end{tabular} \\
\rowcolor[HTML]{FFFFFF} 
\hline{\bf Diversity}                                           & \begin{tabular}[l]{@{}l@{}}Diversity represents the spread of the prop-\\osed solutions. Ideally the solutions should\\be well distributed across the Pareto fro-\\ntier,rather than concentrated in certain\\ regions.\end{tabular}\\ \hline
\end{tabular}
\caption{Performance Measures}
\label{fig:measure}
\end{figure}

\subsection{Setup}

We parallelized GALE using the "island" model\cite{73Latter}. In the "island" approach to parallelization of genetic programming, the population for a given run is divided into semi-isolated subpopulations (called demes). Each subpopulation is assigned to a separate processor of the parallel computing system. The run begins with the one-time random creation of a separate population of individuals at each processor of the parallel computer system. This is a very rudimentary approach and we will be experimenting further using a Master Slave approach.

The parameters we use for Differential Evolution and GALE are shown in figure \ref{fig:de_settings} and figure \ref{fig:gale_settings} respectively.

\begin{figure}[!t]
\centering
\begin{tabular}{|l@{~}|l@{~}|}
\hline
Setting & Value \\ \hline
Population Size               & 100   \\
Number of Generations         & 100   \\
Mutation Rate                 & 0.75  \\ 
Crossover Probability         & 0.3  \\ \hline
\end{tabular}
\caption{Settings for DE}
\label{fig:de_settings}
\end{figure}

\begin{figure}[!t]
\centering
\begin{tabular}{|l@{~}|l@{~}|}
\hline
Setting & Value \\ \hline
Population Size               & 100   \\
Number of Generations         & 100   \\
Domination Factor             & 0.15  \\ \hline 
\end{tabular}
\caption{Settings for GALE}
\label{fig:gale_settings}
\end{figure}

\section{Results}
The results for runtime, convergence and diversity are shown in figure \ref{fig:results_table}. Each optimizer is run over a random initial sample of the population 20 times to get the range of output values. The minimum, median and maximum values among the 20 iterations are shown in figure \ref{fig:results_table}.  As we can see the serialized version of DE yields the lowest convergence. The diversity for all three optimizers are in the same range.

\begin{figure}[!t]
\centering
\begin{tabular}{| >{\tc}m{0.5in} | >{\tc}m{0.75in} | >{\tc}m{0.8in} | >{\tc}m{0.62in} |}
\hline
Algorithm & Runtime(secs) & Convergence & Diversity \\ \hline
DE & \stack{0.45}{0.49}{0.81} & \stack{1.80e-5}{2.23e-5}{2.56e-5} & \stack{0.37}{0.44}{0.54} \\ \hline 
\begin{tabular}[l]{@{}l@{}}GALE\\(Serial)\end{tabular} & \stack{39.30}{42.05}{43.35} & \stack{5.28e-4}{5.49e-4}{5.73e-4} & \stack{0.36}{0.41}{0.49} \\ \hline 
\begin{tabular}[l]{@{}l@{}}GALE\\(Parallel)\end{tabular} & \stack{17.13}{19.11}{20.45} & \stack{5.273-4}{5.54e-4}{5.78e-4} & \stack{0.39}{0.42}{0.51} \\ \hline 
\end{tabular}
\caption{Settings for GALE}
\label{fig:results_table}
\end{figure}


To study the distribution and rank the optimizer over all the 20 runs we use the Scott-Knott procedure recommended by Mittas \& Angelis\cite{mittas13}. This method
sorts a list of $l$ treatments with $ls$ measurements by their median
score. It then
splits $l$ into sub-lists $m,n$ in order to maximize the expected value of
 differences  in the observed performances
before and after divisions. E.g. for lists $l,m,n$ of size $ls,ms,ns$ where $l=m\cup n$:
 \[E(\Delta)=\frac{ms}{ls}abs(m.\mu - l.\mu)^2 + \frac{ns}{ls}abs(n.\mu - l.\mu)^2\]
Scott-Knott then applies some statistical hypothesis test $H$ to check
if $m,n$ are significantly different. If so, Scott-Knott then recurses on each division.
For example, consider the following data collected under different treatments {\em rx}:

{\scriptsize \begin{verbatim}
        rx1 = [0.34, 0.49, 0.51, 0.6]
        rx2 = [0.6,  0.7,  0.8,  0.9]
        rx3 = [0.15, 0.25, 0.4,  0.35]
        rx4=  [0.6,  0.7,  0.8,  0.9]
        rx5=  [0.1,  0.2,  0.3,  0.4]
\end{verbatim}}
\noindent
After sorting and division, Scott-Knott declares:
\bi
\item Ranked \#1 is rx5 with median= 0.25
\item Ranked \#1 is rx3 with median= 0.3
\item Ranked \#2 is rx1 with median= 0.5
\item Ranked \#3 is rx2 with median= 0.75
\item Ranked \#3 is rx4 with median= 0.75
\ei
Note that Scott-Knott found  little
difference between rx5 and rx3. Hence,
they have the same rank, even though their medians differ.

Scott-Knott is better than an 
 all-pairs hypothesis test of all methods; e.g. six treatments
can be compared \mbox{$(6^2-6)/2=15$} ways. 
A 95\% confidence test run for each comparison has  a very low total confidence: 
\mbox{$0.95^{15} = 46$}\%.
To avoid an all-pairs comparison, Scott-Knott only calls on hypothesis
tests {\em after} it has found splits that maximize the performance differences.
 
For this study, our hypothesis test $H$ was a
conjunction of the A12 effect size test of  and
non-parametric bootstrap sampling; i.e. our
Scott-Knott divided the data if {\em both}
bootstrapping and an effect size test agreed that
the division was statistically significant (99\%
confidence) and not a ``small'' effect ($A12 \ge
0.6$).

\begin{figure}[!t]
{\scriptsize \begin{tabular}{l@{~~~}l@{~~~}r@{~~~}r@{~~~}c}
\arrayrulecolor{darkgray}
\rowcolor[gray]{.9}  rank & optimizer & median & IQR & 
%min= 20, max= 117
\\
  1 &      DE(Serial) &    2.23e-5  &  3.04e-6 & \quart{1}{1}{1}{100} \\ \hline
  2 &      GALE(Serial) &    5.49e-4  &  8.72e-6 & \quart{70}{1}{71}{100} \\
  2 &       GALE(Parallel) &    5.54e-4  &  2.21e-5 & \quart{70}{10}{76}{100} \\

\end{tabular}}
\caption{Convergence of Optimizers. }\label{fig:convergence}
\end{figure}

\begin{figure}[!t]
{\scriptsize \begin{tabular}{l@{~~~}l@{~~~}r@{~~~}r@{~~~}c}
\arrayrulecolor{darkgray}
\rowcolor[gray]{.9}  rank & optimizer & median & IQR & 
%min= 20, max= 117
\\
  1 &      DE(Serial) &    0.416  &  0.070 & \quart{35}{41}{46}{100} \\ \hline
  1 &      GALE(Serial) &    0.431  &  0.056 & \quart{38}{43}{48}{100} \\
  1 &      GALE(Parallel) &    0.432  &  0.047 & \quart{39}{43}{48}{100} \\

\end{tabular}}
\caption{Diversity of Optimizers. }\label{fig:diversity}
\end{figure}

We have estimated the Scott-Knott rankings for convergence and diversity for all three of the optimizer methods. We did not estimate it for runtime since DE was almost 50 times faster than GALE, hence there was no statistical signficance to measure it.

From figure \ref{fig:convergence} we can see that the serialized version of DE produces the best result with rank 1, but there is no statistical difference between the serialized and parallel version of GALE in terms of convergence. The black dot in the last column shows the median value of convergence over 20 runs and the line shows the set of values between the 25th and 75th percentile. We can see that the variance for convergence is very small for all the optimizers, since the inter-quartile distance between the 25th and 75th quartile is almost 0.

Figure \ref{fig:diversity} shows that there is no statistical difference in diversity between all the three methods with all of them ranking 1. Similar median and variance can be observed over all the methods

\bibliographystyle{plain}
\bibliography{refs}
\end{document}